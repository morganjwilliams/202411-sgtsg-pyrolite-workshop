{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [Getting Started](./01_jupyter_python.ipynb) | **Examples:** | [Access](./02_accessing_indexing.ipynb) | [Transform](./03_transform.ipynb) | [Plotting](./04_simple_vis.ipynb) | [Norm-Spiders](./05_norm_spiders.ipynb) | [Minerals](./06_minerals.ipynb) | **Workflows:** | [lambdas](./07_lambdas.ipynb) | [CIPW](./08_CIPW_Norm.ipynb)  | [ML](./11_geochem_ML.ipynb) | [Spatial Data](./12_spatial_geochem.ipynb) |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "\n",
    "# Transforming Geochemical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyrolite\n",
    "from synthdata import get_synthetic_data\n",
    "\n",
    "pd.options.display.precision = 3  # smaller graphical outputs\n",
    "\n",
    "# synthetic data with a multivariate normal distribution in log-transformed space\n",
    "df = get_synthetic_data(\n",
    "    columns=[\"CaO\", \"MgO\", \"SiO2\", \"FeO\", \"Na2O\", \"Ni\", \"Ti\", \"La\", \"Lu\", \"Te\"]\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Using Indexers, Scaling\n",
    "\n",
    "You can also use these indexers for assignment, where the dimensionality of the dataset doesn't change. While you can transform elements and oxide abundnace units easily when you remember the relative scales, `pyrolite` provides some functions such that you don't have to rely on your memory. Here we create a copy of the dataframe and within it revert the change we made above - so these should be the orignal ppm values. This method provides an easy way to explicitly declare your intention when changing units - and makes sure the relative scales are correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrolite.util.units import scale\n",
    "\n",
    "# get a copy of just the elements from the dataframe, we'll then edit this version\n",
    "els = df.pyrochem.elements.copy()\n",
    "els"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `scale` function to convert between known unit systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "els.pyrochem.elements * scale(\"ppm\", \"wt%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also assign this in place (`A *= B` is the shorthand equivalent of `A = A * B`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "els.pyrochem.elements *= scale(\"ppm\", \"wt%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pyrochem.elements, els.pyrochem.elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Converting Chemical Components \n",
    "\n",
    "`pyrolite` provides some straightfoward methods to calcuate element-oxide conversions (e.g. to transform Ti abundance to TiO2 abudnance), assuming that the system is open to oxygen (i.e. in this case the extra oxygen will be added to the composition). This interface also allows the user to quickly add ratios and specify redox pairs at the same time. For example, we can transform a copy of our dataframe to include extra ratios and change some of our oxide components to elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pyrochem.convert_chemistry(\n",
    "    to=[\"MgO\", \"SiO2\", \"FeO\", \"Ca\", \"Te\", \"Na\", \"Na/Te\", \"MgO/SiO2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a similar way, we can also specify the molar speciation for redox species (so far just iron; others could be incorporated if they'll be useful). Here we adjust the total iron within our compositions (currently specified as FeO) to have a $Fe^{2+}/Fe^{3+}$ ratio of 9:1 (roughly what you might expect from a ~normal mantle-derived magma) - note that columns which aren't specified as *abundances* (be they metadata or things like ratios) would also be returned here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pyrochem.convert_chemistry(to=[{\"FeO\": 0.9, \"Fe2O3\": 0.1}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<div class='alert alert-warning'> <font size=\"+1\" color=\"black\"><b> Checkpoint & Time Check</b><br>How are things going?</font></div>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compositional Data\n",
    "\n",
    " We only have time to touch on compositional data anlaysis here, but there's a bit more information in [the pyrolite documentation](https://pyrolite.readthedocs.io/en/main/examples/index.html#compositional-data-examples). \n",
    " \n",
    "First, let's look at a simple demonstration of the utility of compositional data analysis at a scale where it's imminently feasible - the measurement and estimation of isotope ratios. While in larger multivariate datasets we often encounter a high relative degree of missing data (one principal hurdle of compositional data analysis), for this scenario we can expect low to no missingness. We'll use a synthetic dataset for demonstration purposes - but we encourage you to try it out on your own dataset!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from synthdata import count_based_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oxygen = count_based_signal(\n",
    "    columns=[\"18O\", \"17O\", \"16O\"],\n",
    "    bias=np.array([np.log(498.81), np.log(0.189)]),\n",
    ")\n",
    "oxygen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we can calculate isotope ratios, and optionally transorm this into delta/permille values relative to a standard reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_18_16 = oxygen[\"18O\"] / oxygen[\"16O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can transform this into a delta representation (relative to a known standard value, which happens to be what we've used as our estimate of composition above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = ((ratio_18_16 / 498.81) - 1) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = delta.plot.hist(bins=20)\n",
    "ax.set(xlabel=r\"$\\delta^{18}O$ ($\\perthousand$)\")\n",
    "ax.axvline(delta.mean(), color=\"k\")\n",
    "for a in [\n",
    "    delta.mean() - delta.std() / (delta.size**0.5),\n",
    "    delta.mean() + delta.std() / (delta.size**0.5),\n",
    "]:\n",
    "    ax.axvline(a, color=\"0.5\", ls=\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_18_16 = ratio_18_16.mean()\n",
    "mean_18_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equally, you could have chosen (if you ignored conventions) to take the ratio of $^{16}O$ and $^{18}O$; and you'd expect that the means are invertible - right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_16_18 = oxygen[\"16O\"] / oxygen[\"18O\"]\n",
    "mean_16_18 = ratio_16_18.mean()\n",
    "mean_16_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which, inverted to give a comparable estimate gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / mean_16_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't quite the same number. In terms of permille, we're around 0.05 ‰ off - not a great deal, but a problem when you're looking to do high precision analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mean_18_16 - (1 / mean_16_18)) / mean_18_16 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what's going on here? These peculiarities result from incorrect assumptions regarding the distribution of the data: ratios of compositional components are typically lognormally distributed, rather than normally distributed, and the compositional components themselves commonly have a Poisson distribution or similar. These distributions contrast significantly with the normal distribution at the core of most statistical tests. To some extent, part of this makes sense - the normal distribution has one immediate failure for geochemical data, in that it has non-zero probability density below 0, and we know that you can’t have negative atoms! We can compare distributions with similar expected values and variances to compare normal, lognormal and Poisson disributions (log-transformed variables below):\n",
    "\n",
    "<img src=\"https://pyrolite.readthedocs.io/en/main/_images/sphx_glr_compositional_data_002.png\" style=\"display:inline; margin: 20px 10px 10px 20px;\" width=\"60%\"/>\n",
    "\n",
    "We can see that by taking the logarithm of the lognormal distribution we find normally distributed variable in log space. If we take the natural logarithm of the ratios before we take an average (accounting for expected log-normal distribution), and then the exponent of the mean - we can see that the situation improves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmean_18_16 = np.exp(np.log(ratio_18_16).mean())\n",
    "logmean_16_18 = np.exp(np.log(ratio_16_18).mean())\n",
    "logmean_18_16, 1 / logmean_16_18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality the magnitude of this difference will be dependent on the range of values within your population; but depending on what you're looking at, this could be significant! It will be a bit different for things with low counts (e.g. Pb/U ratios in geochronology or rare trace elements) or strongly compositionally covariant variables (e.g. major elements, where an increase in one means an equal decrease in the other(s)). Note that this also means the uncertainties on the mean of ratios of compositional variables will be *asymmetric*! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with These Types of Issues in `pyrolite`\n",
    "\n",
    "pyrolite includes a few functions for dealing with compositional data, at the heart of which are i) closure (i.e. everything sums to 100%) and ii) transformation (commonly log-transformations) to deal with\n",
    "the compositional space. \n",
    "\n",
    "The commonly used log-transformations include the Additive Log-Ratio (`ALR`), Centred Log-Ratio (`CLR`), and Isometric Log-Ratio (`ILR`). Let's have a look at one of the log-transforms, which can be accessed directly from your dataframes (via the `df.pyrocomp` API). A key thing to note here is that everything should start in the same units and sum to one if you want it to be able to be back-transformed! Note we're using `df.pyrochem.compositional` to extract the elements and oxides by leave other columns alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df = df.copy()\n",
    "scaled_df.pyrochem.elements *= scale(\"ppm\", \"wt%\")\n",
    "scaled_df.pyrochem.compositional = (\n",
    "    scaled_df.pyrochem.compositional.pyrocomp.renormalise(scale=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = scaled_df.pyrochem.compositional.pyrocomp.CLR()\n",
    "lr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_transformed = lr_df.pyrocomp.inverse_CLR()\n",
    "back_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key areas where these logratio transforms might be useful is in deriving statistical properties from your geochemical data, for example calculating a mean. You could perform the transform, calculate the mean, and perform an inverse transform - but there's also a specific function dedicated to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_df.pyrochem.compositional.pyrocomp.logratiomean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compositional Data - Spherical Transformation\n",
    "\n",
    "pyrolite also includes a spherical transformation, which is particularly useful for scenarios where zeros are valid, which is one scenario where logratio methods fall down (e.g., for mineralogy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphered = scaled_df.pyrochem.compositional.pyrocomp.sphere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphered.pyrocomp.inverse_sphere()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a quick look at how these compare between a 'flat' ternary diagram perspective and the analogous view of the (hyper)spherical variant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pyrolite.plot.color import process_color\n",
    "from pyrolite.util.plot.helpers import init_spherical_octant\n",
    "\n",
    "colors = process_color(scaled_df[\"MgO\"], cmap=\"RdBu\")[\"c\"]\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "ax0 = fig.add_subplot(121)\n",
    "ax1 = fig.add_subplot(122, projection=\"3d\")\n",
    "\n",
    "init_spherical_octant(labels=[c[2:] for c in sphered.columns[:3]], ax=ax1)\n",
    "\n",
    "scaled_df.iloc[:, 1:4].pyroplot.scatter(ax=ax0, c=colors)\n",
    "ax1.scatter(*np.sqrt(scaled_df.values[:, 1:4]).T, c=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [Getting Started](./01_jupyter_python.ipynb) | **Examples:** | [Access](./02_accessing_indexing.ipynb) | [Transform](./03_transform.ipynb) | [Plotting](./04_simple_vis.ipynb) | [Norm-Spiders](./05_norm_spiders.ipynb) | [Minerals](./06_minerals.ipynb) | **Workflows:** | [lambdas](./07_lambdas.ipynb) | [CIPW](./08_CIPW_Norm.ipynb)  | [ML](./11_geochem_ML.ipynb) | [Spatial Data](./12_spatial_geochem.ipynb) |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Bonus: Extra Compositional Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the non-invertibility of means releated to compositional data in a few more examples - here for a less precise dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors = count_based_signal(columns=[\"MgO\", \"CaO\", \"FeO\"], strength=1000)\n",
    "MgFe = majors[\"MgO\"] / majors[\"FeO\"]\n",
    "FeMg = majors[\"FeO\"] / majors[\"MgO\"]\n",
    "ax = MgFe.plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ~0.5% off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(FeMg.mean() * MgFe.mean() - 1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This phenomena occurs regardless of the signal generation process, e.g. generating a signal from random integers with a set initial bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([100, 200, 300]) + np.random.randint(-10, 10, size=(100, 3)).astype(\n",
    "    float\n",
    ")\n",
    "arr /= arr.sum(axis=1)[:, None]\n",
    "int_random_signal = pd.DataFrame(arr, columns=[\"A\", \"B\", \"C\"])\n",
    "int_random_signal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_A = (int_random_signal[\"B\"] / int_random_signal[\"A\"]).mean()\n",
    "A_B = (int_random_signal[\"A\"] / int_random_signal[\"B\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_A.mean()  # should be about 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is 0.4% different to the inverted A/B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(B_A - (1 / A_B)) / B_A * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
