{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [Getting Started](./01_jupyter_python.ipynb) | **Examples:** | [Access](./02_accessing_indexing.ipynb) | [Transform](./03_transform.ipynb) | [Plotting](./04_simple_vis.ipynb) | [Norm-Spiders](./05_norm_spiders.ipynb) | [Minerals](./06_minerals.ipynb) | [lambdas](./07_lambdas.ipynb) | [CIPW](./08_CIPW_Norm.ipynb) | [Lattice Strain](./09_lattice_strain.ipynb) | **Extensions:** | [ML](./11_geochem_ML.ipynb) | [Spatial Data](./12_spatial_geochem.ipynb) |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |\n",
    "\n",
    "# Getting Started with Jupyter and Python\n",
    "\n",
    "\n",
    "**New to Jupyter?**<br>\n",
    "\n",
    "If you're new to Jupyter, the main thing you'll need to know for this set of notebooks is that you can use <code>Shift+Enter</code> to execute cells of code (or press the <i class=\"fas fa-play\"></i> button). This notebook should have launched in Jupyter Lab if you've come via the Binder link; this is an interface which provides a file browser to your left, a main workspace (if you're reading this, the space occupied by this notebook) and organises separate open notebooks in tabs (see above this cell). If you'd like a more detailed overview of the Jupyter interface, you can check out [the respective documentation](https://jupyterlab.readthedocs.io/en/stable/user/interface.html). Jupyter notebooks typically contain both text (markdown, like this one) and executable code cells. Try running the next two, which generate simple output interactively: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Run me with Shift-Enter/Cmd-Enter!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a few conventions are used throughout, code or keyboard commands are typically formatted `in grey boxes`, and where a piece of code refers to something you can change/input, I'll often use references between angular brackets (e.g. `print(\"<thing>\")`, where `<thing>` shouldn't be inserted literally, but instead can be replaced by e.g. `\"Hello world!\"`, giving `print(\"Hello world!\")`). Especially in this notebook, I've used **bold** to highlight some key terms related to core Python basics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What is Jupyter?\n",
    "\n",
    "[Jupyter](https://jupyter.org/) is an ecosystem of open source tools which provide interfaces for working with a variety of programming languages. The most well known of these is the Jupyter notebook - which in its simplest form is an electronic notebook consisting of a series of cells (like this one) which can contain a mix of text, code, output, metadata and potentially even interactive elements. Today we're working in Jupyter Lab - which is an environment which combines an interface to notebooks with a file explorer (left) and enables the integration of a variety of other tools.\n",
    "#### Should you use notebooks?\n",
    "\n",
    "Jupyter notebooks can be a good way to organise prototype workflows, and are often a good mechanism for sharing and explaining your code in a way which invites conversation and interaction (hence using them here!). Notably though, they're not necessarily the solution for everything. While you can construct workflows and models through Jupyter notebooks, they are more difficult to manage relative to standalone scripts and libraries when it comes to version management, integration and automation. For this reason it's suggested that once you have something working well, consider writing it up as a separate script or even a Python library/module!\n",
    "\n",
    "#### Using Notebooks for Today (if you haven't seen them before)\n",
    "\n",
    "The key thing to note for today is that it's common to find a mix of text cells like this one (typically written in [Markdown](https://www.markdownguide.org/) for easy markup of text) and code cells (scroll down a bit, they'll have a grey background). While it's not necessary for today, knowing a bit of markdown syntax can help structure notes and documentation accompanying your code. \n",
    "\n",
    "Code cells are not static - here in the workshop JupyterHub/Binder you can run them (`Shift-Enter` or use the <i class=\"fas fa-play\"></i> button), edit and re-run them! We encourage you to edit, change and break things within reason to get to know the tools (you can always restart Jupyter!).\n",
    "\n",
    "You can tell which cells are being executed by the notation on the left of it - cells already run will have a number (e.g. `[1]`) noting the order in which it was run, cells yet to run will have an asterisk (`[*]`) and cells which haven't been executed will have empty brackets (`[ ]`). Also check the small circle in the upper right - if it's <i class=\"far fa-circle\"></i> then it's stopped/hasn't started executing, if it's <i class=\"fas fa-circle\"></i> it's trying to execute something/busy. If you get stuck and it looks like nothing's happening the kernel might have stalled; you can restart it under the `Kernel` menu to the top left, using `Restart Kernel...`.\n",
    "\n",
    "<div class='alert alert-warning'> <font color=\"black\"><b>Note:</b> Binder will not save/persist your progress or changes outside your session! If you want to keep a modified notebook, you can right click and download from the file browser on the left (or, in Binder - you can also click the download link provided above).</font></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## What is Python?\n",
    "\n",
    "[Python](https://www.python.org/) is a high-level multi-purpose programming language. It's freely and openly available and you'll be able to find a distribution which can run on just about any system (e.g. 'micropython' runs on bare-metal for tiny microcontrollers). There is a large community which uses Python, the majority of which revolves around open-source projects. You can use Python as a fancy calculator, build websites, run servers, build machine learning models, image black holes or provide testing and code generation for an [embedded software framework for NASA](https://github.com/nasa/fprime).\n",
    "\n",
    "Python is an *interpreted* language, which means that rather than being compiled (like e.g. C, C++ and Fortran) it's read, interpreted and executed as needed. For this reason, it'll typically be a bit slower for most task (but not necessarily by much), but it also makes it much less complex to get into, read and run. When working with numerically intense workflows, you're often actually running code which was written in a more performant language in the background - and this bridges a large part of the gap between language 'performance'. Notably, however, Python tends to be written to be later read (or at least it can and should be) - and the accessibility together with it's flexibility are some of the key reasons it's so widely used.\n",
    "\n",
    "You can run Python from the terminal, but typically we want to either write and execute programs (e.g. like 'scripts'; Python is often termed a 'scripting language') or play to the language's strengths and execute code interactively (e.g. in these notebooks!). To do this we need some kind of editor - whether it be notepad, Jupyter Notebooks or a dedicated development environment. While Python is often distributed with some kind of editor, many people have their own favourites - and it tends to depend a bit on what you're doing (e.g. I use 'Atom' to write pyrolite, but write these workshops/demonstrations in Jupyter notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Some Basic Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The typical first line that new Python coders will execute will print the words 'Hello World!':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `print` statement is a useful way to get some quick output from your code, you'll likely end using this a lot! Here the `print` statement is actually a **function** (a specific chunk of code which typically takes some input and generates some output), and we're passing it the **argument** `\"Hello World!\"`, which itself is a **string** (text enclosed by either single or double quotation marks; `\"\"` or `''`). \n",
    "\n",
    "Note that in an **interactive environment** (like this notebook) that the execution of code will typically output the result of the last expression - so here we should also be able to just output the string by having it as the last line in a cell (note the inclusion of the quotation marks denoting the string type, however!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators and Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond using Python as a glorified digital printer, you can also use it as a flexible calculator for just about any kind of numerical task you desire. There are a range of **operators** which when used with numeric types allow you to add, subtract, mutliply, divide and more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 4 - 4 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is a distinction beteween **integers** (type `int`, e.g. `2`) and **floats** type (`float`, e.g. `2.0`), and that depending on the operations used you may get a different type of result than what you put in. Beyond the simple operators for numeric types, there are a few more complicated ones for integer/floor division (`//`), remainder (`%`), exponent (`**`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 // 2, 4 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also operators for equalities: `==` for equal-to, `>` and `,` for greater-than, less-than, `>=` and `<=` for greater-than-or-equal-to and less-than-or-equal-to; these will return a **boolean** (type `bool`, `True` or `False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4 < 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8 >= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond simple numerical calculations and printing, we'll typically want to store the value of some of these expressions as a **variable** - essentially giving it a name. We can then reuse and reassign these variables by referring to them (note these variables persist between cells; they're defined **globally**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2\n",
    "a * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a + 3\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some operators which allow this type of assignment with a type of shorthand, e.g. for incremental addition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a += 1\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you start to get a bit of structure in your code and have multiple variables floating around, it's a good idea to start commenting and documenting your code. To do this, the use of comments and multi-line strings is typical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is a multi-line string to describe the general behaviour of the code to follow below.\n",
    "\"\"\"\n",
    "# this is a comment\n",
    "b = 14\n",
    "# halve b\n",
    "b /= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides types which correspond to an individual value, there are also types of collections of values, including lists, tuples (\"lists which you can't change\"), dictionaries ( key-value pairs), and sets (a collection of unique things)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0 = [\"a\", \"b\", 1, 2]\n",
    "\n",
    "tuple_0 = (\"a\", \"b\", 1, 2)\n",
    "\n",
    "dict_0 = {\"a\": \"b\", 1: 2}\n",
    "\n",
    "set_0 = {\"a\", \"b\", 1, 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refer to/**index** the values within these collections, and in some cases assign new values (note that Python uses 0-based indexing; you need to use 0 to ask for the first element, and so on):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0[0], tuple_0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably, you can't use these indexes to get the elements/values of a dictionary or set; a dictionary has key-value pairs - and you can access the values by using the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_0[\"a\"], dict_0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the last elements of an indexable collection, you can also use negative indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_0[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another handy function for dealing with collections is `len`, which will return the length of a collection (at it's root level):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [[\"b\", \"d\", \"a\"], \"c\", 1, 5.6]\n",
    "len(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first element only counts as one! But we can also check it's length if you wanted to dig into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lst[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loops and Iteration\n",
    "\n",
    "A common construct in many programming languages is a loop, and especially a `for` loop. When we want to iterate through items within an object (like a list), for loops *can* be a useful way to do so (sometimes there are better ways)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\"a\", \"b\", \"c\"]\n",
    "for item in lst:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two other useful things to mention here are `range` and `enumerate`. `range` gives you an ordered set of numbers up to (but not including) the specified maximum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(10):\n",
    "    print(ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`enumerate` gives you an indexed reference to items in a collection, and is often used in for loops. Here we also use some **string formatting** (the `{}` and the `.format(...)`) to print out the indexes and items returned from `enumerate`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, item in enumerate(lst):\n",
    "    print(\"The item at position {} is {}\".format(ix, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something which might be a bit advanced for now, but you'll see a lot of later today and within `pyrolite` is something called **list comprehension**, which is basically a for loop contained within a list. It enables some quick modifications/filtering combined with iterating through collections, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a * 2 for a in lst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use conditional statements within them (the `if`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[a for a in lst if a != \"c\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions \n",
    "Once you start to write a bit of code, you'll notice that a lot of times you'll repeat your self/copy paste code from one script/notebook to another. At this point you should consisder starting to organise code which is run repeatedly into a relevant structure. **Functions** are often the primary structure you'll use to do this - wrapping up and naming a bit of code, defining its input and output. \n",
    "\n",
    "Functions can take a variety of inputs. These inputs which are divided into **arguments** (passed simply as values, typically noted `args`) and **keyword arguments** (key-value pairs, often noted `kwargs`). The following function takes a single unnamed input, modifies it and returns a different value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "add_one(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions need not return a value (e.g. sometimes you want functions to save something to disk, print output or a variety of other use cases), but often do - and can return multiple.\n",
    "\n",
    "It's a good idea to give your functions and their arguments readable names, and document these in docstrings (the multi-line string below). Here we use some conditional statements to control scaling of a number, and add some appropriate documentation for the process: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_wt_percent(\n",
    "    x,\n",
    "    from_units=\"ppm\",  # this is an argument  # this is a keyword argument\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a value to wt%.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float | array\n",
    "        Value to convert units for.\n",
    "    from_units : str\n",
    "        Current units the value is in.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    \"\"\"\n",
    "    if from_units == \"wt%\":\n",
    "        pass\n",
    "    elif from_units == \"ppm\":\n",
    "        x /= 10000\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_wt_percent(10, from_units=\"ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inbuilt Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you write functions with docstrings, you're then also able to access them as needed through built-in help functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(to_wt_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within Jupyter, you can also use some built-in shortcuts (and usually, tab-completion):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_wt_percent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other useful aspect of bundling up your code in this way is that you can save it to a separate file (e.g. we might put the file above in a file called `units.py`), and then import it so you can use it across multiple scripts - or even put together a collection of functions into a library (this is how pyrolite began...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bit of an aside, some additional methods beyond the standard help and inbuilt Jupyter `?` might be useful:\n",
    "* `whos` will give you an indication of existing objects and their types in an interactive Python session (like in Jupyter)\n",
    "* `dir(<object>)` will give you the list of methods and attributes defined for an object, handy for finding what an object can do/has within it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using More of Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great advantages of working with Python is the ecosystem of tools which you can leverage in your own work - from `numpy`, `scipy`, `matplotlib` and `pandas` through to `pyrolite`, which is built upon the others. To be able to use these libraries/packages, you'll need to **import** them. There are a few conventions for importing some common packages to reduce the amount of code you need to type which are handy to recognise. For example, instead of importing `pandas` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import `pandas` *as* `pd` like this, and thereafter reference it using `pd`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, there are conventions for other libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're just after one part of a library, you can import the single class/function/submodule *from* that library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrolite.util.plot import save_figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's lots we haven't covered in much/any detail, including:\n",
    "* classes and objects\n",
    "* reading and writing files\n",
    "* the rest of the standard Python library  ... \n",
    "\n",
    "Feel free to ask about any of this later, or do some online reading!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<div class='alert alert-warning'> <font size=\"+1\" color=\"black\"><b> Checkpoint & Time Check</b><br>How are things going?</font></div>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'><font color='black'>Below we'll have a quick look at the packages that pyrolite is built upon - particularly because pyrolite replicates their API (Application Programming Interface - how you interact with the code) and the outputs of pyrolite are typically objects created using these libraries.</font></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `numpy`\n",
    "\n",
    "`numpy` is a Python package for working with numeric data, with the `numpy.array` being the core type of data you'd likely run into:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[0.6, 1.3, 2.0, 4.1], [0.2, 1.1, 1.9, 3.2]])\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some ways arrays are a lot like lists, but can be quite a bit more performant when you're getting to larger amounts of data - simply because arrays are typically restricted to containing a single type of data, and the shapes which arrays can take are also restricted (e.g. such that for a multidimensional array you'll need to combine sequences of the same length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Getting Started with `pandas`\n",
    "\n",
    "`pandas` is a Python package for working with tabluar data, and in many ways could replace what most folks do in Excel. It provides an interface to your data in such a way that you'll be looking at more than just the numbers (in contrast to numpy), and allows you to index, subset, filter and otherwise manipulate your dataset based on indexes - specifically the column names and index values. Like `numpy`, it has some restrictions on the shape of your data, and values within each column all have the same data type. \n",
    "\n",
    "The core objects you'll likely be working with in `pandas` are `pandas.DataFrame`s. You can build dataframes from a variety of sources - including numpy arrays, but also a number of different file types. `pd.to_<format>` functions similarly save our dataframes into other formats. See the [docs](https://pandas.pydata.org/pandas-docs/stable/io.html) for a list of all the file types `pandas` can read and write. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(arr, columns=[\"A\", \"B\", \"C\", \"D\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the dataframe has the column names we specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But when we look at the `.index` (the other axis of the table), we haven't assigned anything so it'll use a default range of integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a the underlying `numpy` array, we can use `.values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types are based on columnar formats - so there is one for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a lot of cases, rather than constructing dataframes yourself, you'll likely want to read a file. Here we'll be pull in some spinel geochemistry data from Norilsk, which contains data on the geochemical features of spinels found as inclusions within different phases. Note that `pandas` has a [range of import and export options](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) (and `geopandas` - which we might look at towards the end - has more).\n",
    "\n",
    "This data is available as supplementary material in [Schoneveld, L., Barnes, S. J., Williams, M., Le Vaillant, M., and Paterson, D. (2020). Silicate and Oxide Mineral Chemistry and Textures of the Norilsk-Talnakh Ni-Cu-Platinum Group Element Ore-Bearing Intrusions. Economic Geology](http://doi.org/10.5382/econgeo.4747). We can see that each major-element mineral analysis below includes relevant context as to the data source, analysis, thin section location and the enclosing phase within which the spinel sits. The anlyses include major oxdides in weight percent, and calcuated atoms per formula unit (apfu) for each of these cations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/spinel/Schoneveld2020.csv\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes  # note that here 'object' typically refers to strings - always worth checking if your numbers get converted to strings if you have 'NA', '<LOD' etc!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Indexing\n",
    "\n",
    "`pandas` allows you to index data in a number of ways (with a few restrictions). You can access individual columns using `df[\"<column_name>\"]` or `df.column_name` (if there are no spaces in the column name!), which will return a `pandas.Series` (a single column, with the index of the dataframe):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Fe2_apfu\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Fe2_apfu.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access multiple columns at once by indexing with a list rather than a single value, which will return a *view* of the dataframe (you can also do this to return a once-column dataframe!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Fe2_apfu\", \"Fe3_apfu\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you also want to filter the dataframe based on the index (e.g. where a certain criterion is met), you can use the `df.loc` accessor (and in some cases `df.iloc`, where all you care about is the relative positon of columns/rows, and not their names/values). To do this, you can use `df.loc[<index_filter>, <column_filter>]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Mineral == \"spinel\", [c for c in df.columns if \"apfu\" in c]].dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Site.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Exporting Tables\n",
    "\n",
    "In a similar manner to how we imported he CSV file above, we can export our table as-is (e.g. after some modification/cleaning/transformation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Simple Plotting - Getting Started with `matplotlib`\n",
    "\n",
    "`matplotlib` is a fairly extensive library of plotting tools originally written to avoid paying for MATLAB licenses! It's highly customisable (which is why it's used in pyrolite), but can also allow you to quickly produce simple plots from your data without too much fuss. With a bit more work you can be directly making publication quality (or better..) figures.\n",
    "\n",
    "You can use it with array-based data, or if you already have them, use your `pandas` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(df[\"Cr_apfu\"], df[\"Fe2_apfu\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core structures of `matplotlib` are a `figure` (the whole area of all plots) and `axes` (the area pertaining to a single pair of x-y or other axes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, nrows=1)\n",
    "# create a figure with two subplots/axes - note that 'ax' is a collection/array of axes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just one way to create a figure; it can also be used with shorthand `fig, ax = plt.subplots(2, 1, ...)`.\n",
    "\n",
    "On these axes we can add a variety of different plot types, like the scatter plot above or e.g. histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(10, 4))\n",
    "# plot a histogram on the first axis\n",
    "ax[0].hist(df[\"Cr_apfu\"], color=\"seagreen\", bins=10)\n",
    "ax[0].set(ylabel=\"Fequency\", xlabel=\"Cr (apfu)\")  # label the axes\n",
    "# plot a histogram on the second axis\n",
    "ax[1].hist(df[\"Al_apfu\"], color=\"royalblue\", bins=10)\n",
    "ax[1].set(ylabel=\"Fequency\", xlabel=\"Al (apfu)\")  # label the axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "# scatter plot colored by Al2O3\n",
    "cs = ax.scatter(df[\"MgO_pct\"], df[\"FeO_pct\"], c=df[\"Al2O3_pct\"])\n",
    "ax.set(xlabel=\"MgO\", ylabel=\"FeO\")  # get the current axis and set the labels\n",
    "\n",
    "# create a colorbar for the current axes based on the scatter data\n",
    "cb = plt.colorbar(cs, orientation=\"vertical\")\n",
    "# these $ allow you to put subscript/other LaTeX in the labels\n",
    "cb.set_label(\"Al$_2$O$_3$\", fontweight=\"bold\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pandas` API also allows you to directly plot your data from the dataframe itself (this uses matplotlib in the background):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "bins = np.linspace(0, 1.5, 20)\n",
    "\n",
    "subdf = df.groupby(\"Enclosing Phase\").hist(\n",
    "    column=\"Cr_apfu\", alpha=0.5, ax=ax, bins=bins, grid=False\n",
    ")\n",
    "\n",
    "ax.legend(df[\"Enclosing Phase\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cr_apfu\"].groupby(df[\"Site\"]).plot.hist(alpha=0.5, bins=bins)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pyrolite` in many ways aims to replicate this type of API which is centred around your data, allowing you do directly work from dataframes to transform your data and create visualisations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Try playing around with some of the plotting functions above - or others you find through the e.g. `df.plot` interface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<div class='alert alert-warning'> <font size=\"+1\" color=\"black\"><b> Checkpoint & Time Check</b><br>How are things going?</font></div>\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| [**Overview**](./00_overview.ipynb) | [Getting Started](./01_jupyter_python.ipynb) | **Examples:** | [Access](./02_accessing_indexing.ipynb) | [Transform](./03_transform.ipynb) | [Plotting](./04_simple_vis.ipynb) | [Norm-Spiders](./05_norm_spiders.ipynb) | [Minerals](./06_minerals.ipynb) | [lambdas](./07_lambdas.ipynb) | [CIPW](./08_CIPW_Norm.ipynb) | [Lattice Strain](./09_lattice_strain.ipynb) | **Extensions:** | [ML](./11_geochem_ML.ipynb) | [Spatial Data](./12_spatial_geochem.ipynb) |\n",
    "| -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | -- |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyrolite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
